#!/usr/bin/env python3
"""
Script para treinar modelo ML com dados reais do Bi√©
Dataset: malaria_bie.csv (2020-2024, 9 munic√≠pios)
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder
import joblib
import os
from loguru import logger
from datetime import datetime

# Configurar logging
logger.remove()
logger.add(
    lambda msg: print(msg, end=""),
    format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {message}",
    level="INFO"
)

# Caminhos
DATA_PATH = "../data/raw/malaria_bie.csv"
MODEL_PATH = "models/"
PROCESSED_PATH = "../data/processed/"

def load_and_prepare_data():
    """Carrega e prepara os dados reais do Bi√©"""
    logger.info("üìä Carregando dados reais do Bi√©...")
    
    # Carregar dados
    df = pd.read_csv(DATA_PATH)
    logger.info(f"‚úÖ Dataset carregado: {df.shape[0]} registros, {df.shape[1]} colunas")
    
    # Informa√ß√µes b√°sicas
    logger.info(f"üìÖ Per√≠odo: {df['Ano'].min()}-{df['Ano'].max()}")
    logger.info(f"üèòÔ∏è Munic√≠pios: {df['Municipio'].nunique()} - {list(df['Municipio'].unique())}")
    logger.info(f"üìà Total de casos: {df['Casos_Malaria'].sum():,}")
    logger.info(f"üéØ Classes de risco: {df['Risco'].value_counts().to_dict()}")
    
    return df

def create_features(df):
    """Cria features para o modelo ML"""
    logger.info("üîß Criando features...")
    
    df_features = df.copy()
    
    # 1. Features temporais
    df_features['ano_semana'] = df_features['Ano'].astype(str) + '-' + df_features['Semana'].astype(str).str.zfill(2)
    
    # Features c√≠clicas para sazonalidade
    df_features['semana_sin'] = np.sin(2 * np.pi * df_features['Semana'] / 52)
    df_features['semana_cos'] = np.cos(2 * np.pi * df_features['Semana'] / 52)
    
    # Tend√™ncia temporal
    df_features['tendencia'] = (df_features['Ano'] - df_features['Ano'].min()) * 52 + df_features['Semana']
    
    # Esta√ß√£o do ano (aproximada)
    df_features['estacao'] = ((df_features['Semana'] - 1) // 13) + 1
    
    # 2. Features clim√°ticas
    # Temperatura normalizada
    df_features['temp_norm'] = (df_features['Temperatura_Media_C'] - df_features['Temperatura_Media_C'].mean()) / df_features['Temperatura_Media_C'].std()
    
    # Precipita√ß√£o normalizada
    df_features['precip_norm'] = (df_features['Precipitacao_mm'] - df_features['Precipitacao_mm'].mean()) / df_features['Precipitacao_mm'].std()
    
    # 3. Features de lag (casos da semana anterior)
    df_features = df_features.sort_values(['Municipio', 'Ano', 'Semana'])
    df_features['casos_lag1'] = df_features.groupby('Municipio')['Casos_Malaria'].shift(1)
    df_features['casos_lag2'] = df_features.groupby('Municipio')['Casos_Malaria'].shift(2)
    
    # 4. Features de m√©dia m√≥vel
    df_features['casos_ma3'] = df_features.groupby('Municipio')['Casos_Malaria'].rolling(window=3, min_periods=1).mean().reset_index(0, drop=True)
    df_features['casos_ma5'] = df_features.groupby('Municipio')['Casos_Malaria'].rolling(window=5, min_periods=1).mean().reset_index(0, drop=True)
    
    # 5. Features de munic√≠pio (encoding)
    le_municipio = LabelEncoder()
    df_features['municipio_encoded'] = le_municipio.fit_transform(df_features['Municipio'])
    
    # 6. Features de intera√ß√£o
    df_features['temp_precip_interaction'] = df_features['Temperatura_Media_C'] * df_features['Precipitacao_mm']
    df_features['casos_temp_interaction'] = df_features['Casos_Malaria'] * df_features['Temperatura_Media_C']
    
    # Preencher NaNs dos lags
    df_features['casos_lag1'] = df_features['casos_lag1'].fillna(df_features['Casos_Malaria'].mean())
    df_features['casos_lag2'] = df_features['casos_lag2'].fillna(df_features['Casos_Malaria'].mean())
    
    logger.info(f"‚úÖ Features criadas: {df_features.shape[1]} colunas")
    
    return df_features, le_municipio

def prepare_model_data(df_features):
    """Prepara dados para treinamento do modelo"""
    logger.info("üéØ Preparando dados para treinamento...")
    
    # Features para o modelo
    feature_columns = [
        'Ano', 'Semana', 'Temperatura_Media_C', 'Precipitacao_mm',
        'semana_sin', 'semana_cos', 'tendencia', 'estacao',
        'temp_norm', 'precip_norm', 'casos_lag1', 'casos_lag2',
        'casos_ma3', 'casos_ma5', 'municipio_encoded',
        'temp_precip_interaction', 'casos_temp_interaction'
    ]
    
    X = df_features[feature_columns]
    y = df_features['Risco']
    
    # Encoding da vari√°vel target
    le_risco = LabelEncoder()
    y_encoded = le_risco.fit_transform(y)
    
    logger.info(f"üìä Features: {X.shape[1]}")
    logger.info(f"üéØ Classes: {le_risco.classes_}")
    logger.info(f"üìà Distribui√ß√£o: {np.bincount(y_encoded)}")
    
    return X, y_encoded, feature_columns, le_risco

def train_model(X, y):
    """Treina o modelo Random Forest"""
    logger.info("ü§ñ Treinando modelo Random Forest...")
    
    # Split dos dados
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    logger.info(f"üìä Treino: {X_train.shape[0]} amostras")
    logger.info(f"üìä Teste: {X_test.shape[0]} amostras")
    
    # Modelo Random Forest
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    )
    
    # Treinamento
    model.fit(X_train, y_train)
    
    # Predi√ß√µes
    y_pred = model.predict(X_test)
    
    # M√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    logger.info(f"üéØ Acur√°cia: {accuracy:.3f}")
    
    # Cross-validation
    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
    logger.info(f"üìä CV Score (m√©dia): {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
    
    return model, X_test, y_test, y_pred, accuracy, cv_scores

def evaluate_model(model, X_test, y_test, y_pred, le_risco, feature_columns):
    """Avalia o modelo e gera relat√≥rio detalhado"""
    logger.info("üìä Avaliando modelo...")
    
    # Relat√≥rio de classifica√ß√£o
    print("\n" + "="*60)
    print("üìä RELAT√ìRIO DE CLASSIFICA√á√ÉO")
    print("="*60)
    print(classification_report(y_test, y_pred, target_names=le_risco.classes_))
    
    # Matriz de confus√£o
    print("\n" + "="*40)
    print("üîç MATRIZ DE CONFUS√ÉO")
    print("="*40)
    cm = confusion_matrix(y_test, y_pred)
    print(cm)
    
    # Feature importance
    print("\n" + "="*50)
    print("üîç TOP 10 FEATURES MAIS IMPORTANTES")
    print("="*50)
    importance_df = pd.DataFrame({
        'feature': feature_columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    for i, (_, row) in enumerate(importance_df.head(10).iterrows()):
        print(f"{i+1:2d}. {row['feature']:25s}: {row['importance']:.3f}")
    
    return importance_df

def save_model_and_data(model, le_risco, le_municipio, importance_df, accuracy, cv_scores):
    """Salva modelo e dados processados"""
    logger.info("üíæ Salvando modelo e dados...")
    
    # Criar diret√≥rios
    os.makedirs(MODEL_PATH, exist_ok=True)
    os.makedirs(PROCESSED_PATH, exist_ok=True)
    
    # Salvar modelo
    model_file = os.path.join(MODEL_PATH, "malaria_risk_model_real.pkl")
    joblib.dump(model, model_file)
    logger.info(f"‚úÖ Modelo salvo: {model_file}")
    
    # Salvar encoders
    joblib.dump(le_risco, os.path.join(MODEL_PATH, "label_encoder_risco.pkl"))
    joblib.dump(le_municipio, os.path.join(MODEL_PATH, "label_encoder_municipio.pkl"))
    
    # Salvar feature importance
    importance_df.to_csv(os.path.join(PROCESSED_PATH, "feature_importance_real.csv"), index=False)
    
    # Salvar m√©tricas
    metrics = {
        'accuracy': accuracy,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'timestamp': datetime.now().isoformat(),
        'model_type': 'RandomForestClassifier',
        'dataset': 'malaria_bie.csv'
    }
    
    pd.DataFrame([metrics]).to_csv(os.path.join(PROCESSED_PATH, "model_metrics_real.csv"), index=False)
    
    logger.info("‚úÖ Todos os arquivos salvos!")

def main():
    """Fun√ß√£o principal"""
    logger.info("üöÄ Iniciando treinamento com dados reais do Bi√©...")
    
    try:
        # 1. Carregar dados
        df = load_and_prepare_data()
        
        # 2. Criar features
        df_features, le_municipio = create_features(df)
        
        # 3. Preparar dados para modelo
        X, y, feature_columns, le_risco = prepare_model_data(df_features)
        
        # 4. Treinar modelo
        model, X_test, y_test, y_pred, accuracy, cv_scores = train_model(X, y)
        
        # 5. Avaliar modelo
        importance_df = evaluate_model(model, X_test, y_test, y_pred, le_risco, feature_columns)
        
        # 6. Salvar modelo e dados
        save_model_and_data(model, le_risco, le_municipio, importance_df, accuracy, cv_scores)
        
        logger.info("üéâ Treinamento conclu√≠do com sucesso!")
        
        # Resumo final
        print("\n" + "="*60)
        print("üéâ RESUMO DO TREINAMENTO")
        print("="*60)
        print(f"üìä Dataset: {df.shape[0]} registros, {df.shape[1]} colunas")
        print(f"üèòÔ∏è Munic√≠pios: {df['Municipio'].nunique()}")
        print(f"üìÖ Per√≠odo: {df['Ano'].min()}-{df['Ano'].max()}")
        print(f"üéØ Acur√°cia: {accuracy:.3f}")
        print(f"üìä CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})")
        print(f"üîç Features: {len(feature_columns)}")
        print(f"üíæ Modelo salvo em: {MODEL_PATH}")
        
    except Exception as e:
        logger.error(f"‚ùå Erro durante treinamento: {e}")
        raise

if __name__ == "__main__":
    main()
